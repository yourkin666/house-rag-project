#!/usr/bin/env python3
"""
é‡æ’åºä¼˜åŒ–æ•ˆæœæµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. æµ‹è¯•åŸºç¡€åˆ†æ•°èåˆæ•ˆæœ
2. éªŒè¯ä»·æ ¼è¯„åˆ†æœºåˆ¶ä¼˜åŒ–
3. æµ‹è¯•å¦å®šæ¡ä»¶å¤„ç†
4. éªŒè¯ä½ç½®æ¨¡ç³ŠåŒ¹é…
5. å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ•ˆæœ

ä½¿ç”¨æ–¹æ³•ï¼š
- ç¡®ä¿å·²å®Œæˆæ··åˆæœç´¢éƒ¨ç½²
- python test_reranking_optimization.py
"""

import sys
import os
import logging
from typing import List, Dict, Any
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, project_root)

from src.house_rag.core.embeddings import rag_service
from src.house_rag.core.database import db_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RerankingOptimizationTester:
    """é‡æ’åºä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_cases = [
            # ä»·æ ¼ä¼˜åŒ–æµ‹è¯•
            {
                "name": "ä»·æ ¼æ¥è¿‘åº¦æµ‹è¯•",
                "query": "æµ¦ä¸œæ–°åŒº1000ä¸‡å·¦å³çš„æˆ¿å­",
                "expected_improvements": ["ä»·æ ¼è¯„åˆ†æ›´ç²¾ç¡®", "æ¥è¿‘ç†æƒ³ä»·æ ¼çš„æˆ¿æºæ’åæ›´é«˜"]
            },
            # å¦å®šæ¡ä»¶æµ‹è¯•
            {
                "name": "å¦å®šæ¡ä»¶å¤„ç†",
                "query": "é™å®‰åŒºå­¦åŒºæˆ¿ï¼Œä½†ä¸è¦åµé—¹çš„ç¯å¢ƒ",
                "expected_improvements": ["é¿å…åµé—¹ç¯å¢ƒ", "æ’é™¤æœ‰å™ªéŸ³å…³é”®è¯çš„æˆ¿æº"]
            },
            # ä½ç½®æ¨¡ç³ŠåŒ¹é…æµ‹è¯•
            {
                "name": "ä½ç½®æ¨¡ç³ŠåŒ¹é…",
                "query": "æ‰¾ä¸ªå¾å®¶æ±‡çš„æˆ¿å­",  # æµ‹è¯•"å¾å®¶æ±‡"æ˜¯å¦èƒ½åŒ¹é…"å¾æ±‡åŒº"
                "expected_improvements": ["å¤„ç†åœ°ååˆ«å", "æ¨¡ç³ŠåŒ¹é…ä½ç½®å…³é”®è¯"]
            },
            # ç»¼åˆæµ‹è¯•
            {
                "name": "ç»¼åˆä¼˜åŒ–æ•ˆæœ",
                "query": "æµ¦ä¸œ800-1200ä¸‡çš„åˆ«å¢…ï¼Œè¿œç¦»å·¥å‚",
                "expected_improvements": ["ä»·æ ¼èŒƒå›´è¯„åˆ†", "å¦å®šæ¡ä»¶å¤„ç†", "æˆ¿å±‹ç±»å‹åŒ¹é…"]
            }
        ]
    
    def test_price_scoring_optimization(self):
        """æµ‹è¯•ä»·æ ¼è¯„åˆ†ä¼˜åŒ–"""
        print("\nğŸ¯ æµ‹è¯•ä»·æ ¼è¯„åˆ†ä¼˜åŒ–")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿæœç´¢å‚æ•°
        search_params = {
            'price_range': (800, 1200),  # 800-1200ä¸‡
        }
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        from langchain_core.documents import Document
        test_docs = [
            Document(
                page_content="è±ªååˆ«å¢…ï¼Œä½ç½®ä¼˜è¶Š",
                metadata={'property_id': 1, 'price': 1000, 'title': 'ç†æƒ³ä»·æ ¼æˆ¿æº'}
            ),
            Document(
                page_content="ç²¾è£…å…¬å¯“ï¼Œäº¤é€šä¾¿åˆ©", 
                metadata={'property_id': 2, 'price': 900, 'title': 'æ¥è¿‘ç†æƒ³ä»·æ ¼'}
            ),
            Document(
                page_content="å­¦åŒºæˆ¿ï¼Œæ•™è‚²èµ„æºä¸°å¯Œ",
                metadata={'property_id': 3, 'price': 1300, 'title': 'è¶…å‡ºé¢„ç®—10%'}
            ),
            Document(
                page_content="å¸‚ä¸­å¿ƒä½å®…",
                metadata={'property_id': 4, 'price': 1400, 'title': 'è¶…å‡ºé¢„ç®—è¿‡å¤š'}
            ),
        ]
        
        # æµ‹è¯•é‡æ’åº
        reranked_docs = rag_service._rerank_and_filter(test_docs, search_params)
        
        print("ä»·æ ¼è¯„åˆ†ç»“æœï¼ˆæŒ‰æ’åºï¼‰:")
        for i, doc in enumerate(reranked_docs, 1):
            price = doc.metadata.get('price')
            title = doc.metadata.get('title')
            print(f"  {i}. {title}: {price}ä¸‡")
        
        # éªŒè¯ç»“æœ
        if reranked_docs:
            top_price = reranked_docs[0].metadata.get('price')
            if 800 <= top_price <= 1200:
                print("âœ… ä»·æ ¼è¯„åˆ†ä¼˜åŒ–æœ‰æ•ˆï¼šé¢„ç®—å†…æˆ¿æºæ’åé å‰")
            else:
                print("âš ï¸ ä»·æ ¼è¯„åˆ†å¯èƒ½éœ€è¦è°ƒæ•´")
    
    def test_negative_conditions(self):
        """æµ‹è¯•å¦å®šæ¡ä»¶å¤„ç†"""
        print("\nğŸš« æµ‹è¯•å¦å®šæ¡ä»¶å¤„ç†")
        print("=" * 50)
        
        search_params = {
            'special_requirements': ['å­¦åŒºæˆ¿', 'ä¸è¦åµé—¹çš„ç¯å¢ƒ', 'é¿å…å·¥å‚é™„è¿‘']
        }
        
        from langchain_core.documents import Document
        test_docs = [
            Document(
                page_content="ä¼˜è´¨å­¦åŒºæˆ¿ï¼Œç¯å¢ƒå®‰é™ï¼Œç»¿åŒ–è‰¯å¥½",
                metadata={'property_id': 1, 'title': 'ç†æƒ³æˆ¿æº'}
            ),
            Document(
                page_content="å­¦åŒºæˆ¿ï¼Œé è¿‘é«˜æ¶æ¡¥ï¼Œäº¤é€šä¾¿åˆ©ä½†è¾ƒåµé—¹",
                metadata={'property_id': 2, 'title': 'åŒ…å«å¦å®šè¯çš„æˆ¿æº'}
            ),
            Document(
                page_content="å­¦åŒºæˆ¿ï¼Œé™„è¿‘æœ‰åŒ–å·¥å‚ï¼Œä»·æ ¼ä¾¿å®œ",
                metadata={'property_id': 3, 'title': 'åŒ…å«å·¥å‚çš„æˆ¿æº'}
            ),
        ]
        
        # æµ‹è¯•å¦å®šå…³é”®è¯æå–
        negative_keywords = rag_service._extract_negative_keywords(search_params)
        print(f"æå–çš„å¦å®šå…³é”®è¯: {negative_keywords}")
        
        # æµ‹è¯•é‡æ’åº
        reranked_docs = rag_service._rerank_and_filter(test_docs, search_params)
        
        print("å¦å®šæ¡ä»¶å¤„ç†ç»“æœ:")
        for i, doc in enumerate(reranked_docs, 1):
            title = doc.metadata.get('title')
            print(f"  {i}. {title}")
        
        # éªŒè¯æ’åºæ˜¯å¦åˆç†
        if reranked_docs and reranked_docs[0].metadata.get('title') == 'ç†æƒ³æˆ¿æº':
            print("âœ… å¦å®šæ¡ä»¶å¤„ç†æœ‰æ•ˆï¼šä¸å«å¦å®šå…³é”®è¯çš„æˆ¿æºæ’åæœ€é«˜")
        else:
            print("âš ï¸ å¦å®šæ¡ä»¶å¤„ç†å¯èƒ½éœ€è¦è°ƒæ•´")
    
    def test_location_fuzzy_matching(self):
        """æµ‹è¯•ä½ç½®æ¨¡ç³ŠåŒ¹é…"""
        print("\nğŸ—ºï¸ æµ‹è¯•ä½ç½®æ¨¡ç³ŠåŒ¹é…")
        print("=" * 50)
        
        search_params = {
            'location_keywords': ['å¾å®¶æ±‡', 'å¸‚ä¸­å¿ƒ']
        }
        
        from langchain_core.documents import Document
        test_docs = [
            Document(
                page_content="ç²¾è£…å…¬å¯“ï¼Œäº¤é€šä¾¿åˆ©",
                metadata={'property_id': 1, 'location': 'ä¸Šæµ·å¸‚å¾æ±‡åŒº', 'title': 'å¾æ±‡åŒºæˆ¿æº'}
            ),
            Document(
                page_content="å•†åŠ¡åŠå…¬æ¥¼",
                metadata={'property_id': 2, 'location': 'ä¸Šæµ·å¸‚é»„æµ¦åŒº', 'title': 'é»„æµ¦åŒºæˆ¿æº'}
            ),
            Document(
                page_content="ä½å®…å°åŒº",
                metadata={'property_id': 3, 'location': 'ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒº', 'title': 'æµ¦ä¸œæˆ¿æº'}
            ),
        ]
        
        # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        similarity1 = rag_service._calculate_location_similarity('å¾å®¶æ±‡', 'ä¸Šæµ·å¸‚å¾æ±‡åŒº')
        similarity2 = rag_service._calculate_location_similarity('å¸‚ä¸­å¿ƒ', 'ä¸Šæµ·å¸‚é»„æµ¦åŒº')
        
        print(f"'å¾å®¶æ±‡' vs 'ä¸Šæµ·å¸‚å¾æ±‡åŒº' ç›¸ä¼¼åº¦: {similarity1:.2f}")
        print(f"'å¸‚ä¸­å¿ƒ' vs 'ä¸Šæµ·å¸‚é»„æµ¦åŒº' ç›¸ä¼¼åº¦: {similarity2:.2f}")
        
        # æµ‹è¯•é‡æ’åº
        reranked_docs = rag_service._rerank_and_filter(test_docs, search_params)
        
        print("ä½ç½®åŒ¹é…ç»“æœ:")
        for i, doc in enumerate(reranked_docs, 1):
            location = doc.metadata.get('location')
            title = doc.metadata.get('title')
            print(f"  {i}. {title}: {location}")
        
        if similarity1 > 0.7:
            print("âœ… ä½ç½®æ¨¡ç³ŠåŒ¹é…æœ‰æ•ˆï¼šèƒ½å¤Ÿå¤„ç†åœ°ååˆ«å")
        else:
            print("âš ï¸ ä½ç½®æ¨¡ç³ŠåŒ¹é…å¯èƒ½éœ€è¦è°ƒæ•´")
    
    def test_comprehensive_optimization(self):
        """ç»¼åˆæµ‹è¯•æ‰€æœ‰ä¼˜åŒ–"""
        print("\nğŸ”„ ç»¼åˆä¼˜åŒ–æ•ˆæœæµ‹è¯•")
        print("=" * 50)
        
        for test_case in self.test_cases:
            print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹: {test_case['name']}")
            print(f"æŸ¥è¯¢: {test_case['query']}")
            
            try:
                # æ‰§è¡ŒçœŸå®æœç´¢
                response = rag_service.ask_question(test_case['query'], max_results=5)
                properties = response.get('retrieved_properties', [])
                
                print(f"æ‰¾åˆ° {len(properties)} ä¸ªæˆ¿æº:")
                for i, prop in enumerate(properties[:3], 1):
                    title = prop.get('title', 'N/A')
                    price = prop.get('price', 'N/A')
                    location = prop.get('location', 'N/A')
                    match_score = prop.get('match_score', 'N/A')
                    
                    print(f"  {i}. {title}")
                    print(f"     ä»·æ ¼: {price}ä¸‡, ä½ç½®: {location}")
                    print(f"     åŒ¹é…åº¦: {match_score}")
                
                print(f"æœŸæœ›æ”¹è¿›: {', '.join(test_case['expected_improvements'])}")
                print("âœ… æµ‹è¯•å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    def test_performance_comparison(self):
        """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        print("\nğŸ“Š é‡æ’åºæ€§èƒ½åˆ†æ")
        print("=" * 50)
        
        # æ£€æŸ¥é‡æ’åºç»Ÿè®¡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if hasattr(rag_service, 'rerank_stats'):
            stats = rag_service.rerank_stats
            print(f"é‡æ’åºç»Ÿè®¡:")
            for key, value in stats.items():
                print(f"  {key}: {value}")
        
        # æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•
        import time
        from langchain_core.documents import Document
        
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ–‡æ¡£
        test_docs = []
        for i in range(50):
            doc = Document(
                page_content=f"æµ‹è¯•æˆ¿æº{i}çš„è¯¦ç»†æè¿°",
                metadata={
                    'property_id': i,
                    'price': 800 + (i * 10),
                    'location': f'æµ‹è¯•åŒºåŸŸ{i % 5}',
                    'hybrid_score': 1.0 - (i * 0.01)  # æ¨¡æ‹Ÿæ··åˆæœç´¢åˆ†æ•°
                }
            )
            test_docs.append(doc)
        
        search_params = {
            'price_range': (900, 1100),
            'location_keywords': ['æµ‹è¯•åŒºåŸŸ1'],
            'special_requirements': ['ä¼˜è´¨']
        }
        
        # æµ‹è¯•é‡æ’åºæ€§èƒ½
        start_time = time.time()
        reranked_docs = rag_service._rerank_and_filter(test_docs, search_params)
        end_time = time.time()
        
        print(f"å¤„ç† {len(test_docs)} ä¸ªæ–‡æ¡£ç”¨æ—¶: {(end_time - start_time)*1000:.2f}ms")
        print(f"è¿”å› {len(reranked_docs)} ä¸ªä¼˜è´¨ç»“æœ")
        print(f"å¹³å‡æ¯ä¸ªæ–‡æ¡£å¤„ç†æ—¶é—´: {((end_time - start_time)/len(test_docs))*1000:.2f}ms")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ é‡æ’åºä¼˜åŒ–æ•ˆæœæµ‹è¯•")
        print("=" * 60)
        
        # æ£€æŸ¥å‰ç½®æ¡ä»¶
        if not self.check_prerequisites():
            print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œæµ‹è¯•ä¸­æ­¢")
            return
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_price_scoring_optimization()
        self.test_negative_conditions()
        self.test_location_fuzzy_matching()
        self.test_comprehensive_optimization()
        self.test_performance_comparison()
        
        print("\n" + "=" * 60)
        print("âœ¨ é‡æ’åºä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ“ˆ ä¸»è¦æ”¹è¿›:")
        print("  1. âœ… èåˆæ··åˆæœç´¢åˆ†æ•°ä½œä¸ºåŸºç¡€åˆ†")
        print("  2. âœ… è¿ç»­çš„ä»·æ ¼æ¥è¿‘åº¦è¯„åˆ†")
        print("  3. âœ… æ™ºèƒ½å¦å®šæ¡ä»¶å¤„ç†")
        print("  4. âœ… ä½ç½®æ¨¡ç³ŠåŒ¹é…èƒ½åŠ›")
        print("  5. âœ… æ›´ç²¾ç¡®çš„ç»¼åˆæ’åº")
        
    def check_prerequisites(self) -> bool:
        """æ£€æŸ¥æµ‹è¯•å‰ç½®æ¡ä»¶"""
        try:
            print("ğŸ“‹ æ£€æŸ¥æµ‹è¯•å‰ç½®æ¡ä»¶...")
            
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            if not db_manager.test_connection():
                print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
                return False
            
            # æ£€æŸ¥é‡æ’åºæ–¹æ³•æ˜¯å¦å­˜åœ¨
            if not hasattr(rag_service, '_rerank_and_filter'):
                print("âŒ é‡æ’åºæ–¹æ³•æœªæ‰¾åˆ°")
                return False
            
            # æ£€æŸ¥æ–°å¢çš„æ–¹æ³•
            required_methods = [
                '_extract_negative_keywords',
                '_calculate_location_similarity',
                '_simple_string_similarity'
            ]
            
            for method in required_methods:
                if not hasattr(rag_service, method):
                    print(f"âŒ æ–¹æ³• {method} æœªæ‰¾åˆ°")
                    return False
            
            print("âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    tester = RerankingOptimizationTester()
    tester.run_all_tests()


if __name__ == "__main__":
    main()
